{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando uma Deep Learning do zero em Python\n",
    "\n",
    "**MNIST:** reconhecer números escritos a mão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c pytorch pytorch\n",
    "# conda install -c pytorch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "# pytorch \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo a conversão de imagem para tensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# carrega a parte de treino do dataset - download e salva na pasta MNIST_data\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n",
    "\n",
    "# cria um buffer para pegar os dados por partes\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# carrega a parte de validação do dataset\n",
    "valset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)\n",
    "\n",
    "# cria um buffer para pegar os dados por partes\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18113c64b20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# representação de um digito so para ver o dado\n",
    "dataiter = iter(trainloader)\n",
    "imagens, etiqueta = next(dataiter)\n",
    "\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# conferir o tamanho do tensor que representa uma imagem\n",
    "# verificar as dimensões do tensor de cada imagem\n",
    "print(imagens[0].shape)\n",
    "# verificar as dimensões do tensor de cada etiqueta\n",
    "print(etiqueta[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Iniciando a Rede\n",
    "\n",
    "keras inception v3\n",
    "\n",
    "<https://keras.io/api/applications/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        # camada de entrada, 784 neuronios que se ligam a 128\n",
    "        self.linear1 = nn.Linear(28*28, 128)\n",
    "        # camada interna 1, 128 neuronios que se ligam a 64\n",
    "        self.linear2 = nn.Linear(128, 64)\n",
    "        # camada interna 2, 64 neuronios que se ligam a 10\n",
    "        self.linear3 = nn.Linear(64,10)\n",
    "        # para camada de saida não é necessário definir nda pois só precisamos pegar o output da camada interna 2\n",
    "\n",
    "        def forward(self, X):\n",
    "            # função de ativação da camada de entrada para a camada interna 1\n",
    "            X = F.relu(self.linear1(X))\n",
    "            # função de ativação da camada de interna 1 para a camada interna 2\n",
    "            X = F.relu(self.linear2(X))\n",
    "            # função de ativação da camada de interna 2 para a camada de saída, necesse caso f(x) = x\n",
    "            X = F.relu(self.linear3(X))\n",
    "            # dados utilizados para calcular a perda\n",
    "            return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otimização da Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "  # define a politica de atualização dos pesos e da bias\n",
    "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) \n",
    "  # timer para saber quanto tempo levou o treino\n",
    "  inicio = time() \n",
    "  # definindo o criterio para calcular a perda\n",
    "  criterio = nn.NLLLoss() \n",
    "  # numero de epochs que o algoritmo rodará - tempo de treinamento - epoca \n",
    "  # um bom treinamento é no minimo de 100\n",
    "  EPOCHS = 100 \n",
    "  # ativando o modo de treinamento do modelo\n",
    "  modelo.train()\n",
    "\n",
    "   \n",
    "  for epoch in range(EPOCHS):\n",
    "    # inicialização da perda acumulada da epoch em questão\n",
    "    perda_acumulada =0 \n",
    "    for imagens, etiquetas in trainloader:\n",
    "      # convertendo as imagens para vetores de 28*28 casas\n",
    "      imagens = imagens.view(imagens.shape[0], -1) \n",
    "      # zerando os gradientes por conta do ciclo anterior\n",
    "      otimizador.zero_grad() \n",
    "      # colocando os dados no modelo\n",
    "      output = modelo(imagens.to(device)) \n",
    "      # calculando a perda da epoch em questão\n",
    "      perda_instantanea = criterio(output, etiquetas.to(device)) \n",
    "      # back propagation a partir da perda\n",
    "      perda_instantanea.backward() \n",
    "      # atualizando os pesos e a bias\n",
    "      otimizador.step() \n",
    "      # atualização da perda acumulada\n",
    "      perda_acumulada += perda_instantanea.item() \n",
    "    else:\n",
    "      print(\"Epoch {} - perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
    "  print(\"\\nTempo de treino (em minutos) = \",(time()-inicio)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar a acuracia\n",
    "\n",
    "Comparar a imagem que não foi treinada com a rede e seus pesos de treinamento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, valloader, device):\n",
    "  conta_corretas, conta_todas = 0, 0\n",
    "  for imagens,etiquetas in valloader:\n",
    "    for i in range(len(etiquetas)):\n",
    "      img = imagens[i].view(1, 784)\n",
    "      #desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
    "      with torch.no_grad():\n",
    "        logps = modelo(img.to(device)) # output do modelo em escala logaritmica\n",
    "      # converte output para escala normal( lembrando que é um tensor)\n",
    "      ps = torch.exp(logps) \n",
    "      probab = list(ps.cpu().numpy()[0])\n",
    "      # converte o tensor em um número, no caso, o numero que o modelo previu\n",
    "      etiqueta_pred = probab.index(max(probab)) \n",
    "      etiqueta_certa = etiquetas.numpy()[i]\n",
    "      #compara a previsão com o valor correto\n",
    "      if(etiqueta_certa == etiqueta_pred):  \n",
    "        conta_corretas += 1\n",
    "      conta_todas += 1\n",
    "  \n",
    "  print(\"Total de imagens testadas =\", conta_todas)\n",
    "  print(\"\\nPrecisão do modelo = {} %\".format((conta_corretas*100)/conta_todas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "# verificar se tem o cuda disponivel, se não vai ser pela cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamar o treino do modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "725b19ffb05f04961e50dd4197e5dfd79ed8318f8496184ac41b1ab3a1bb8c52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
